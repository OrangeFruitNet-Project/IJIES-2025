## ðŸŸ  OrangeFruitNet â€“ Real-Time Deployment Guide

### ðŸ“˜ Overview
This guide documents the inference and deployment procedures for the **OrangeFruitNet** framework on embedded devices such as **NVIDIA Jetson Nano** and **Raspberry Pi 4**, reproducing the results reported in  
ðŸ“„ *OrangeFruitNet: YOLO-Based Orange Fruit Detection and Yield Estimation in Orchard Environments* (IJIES 2025).

All models were exported to **TorchScript** for device-friendly execution with reduced memory footprint and improved portability.

---

### âš™ï¸ 1  Environment Setup

#### ðŸ§© Dependencies
Install Python â‰¥ 3.8 and the required libraries:

```bash
pip install ultralytics torch torchvision opencv-python numpy
```

> ðŸ’¡ On Jetson Nano, use NVIDIAâ€™s JetPack >= 5.0 which includes CUDA-enabled PyTorch.

#### ðŸ“‚ Directory Structure
```
OrangeFruitNet-Project/
â”‚
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ yolov8n.pt
â”‚   â”œâ”€â”€ yolov5s.pt
â”‚   â”œâ”€â”€ yolov4.weights
â”‚   â”œâ”€â”€ faster_rcnn.pth
â”‚   â”œâ”€â”€ mask_rcnn.pth
â”‚   â””â”€â”€ checksums.txt
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ export_torchscript.py
â”‚   â”œâ”€â”€ inference_device.py
â”‚   â””â”€â”€ README_deployment.md
```

---

### ðŸ§  2  Model Export (TorchScript)

Export trained YOLO models to TorchScript for embedded inference:

```bash
python deployment/export_torchscript.py --weights weights/yolov8n.pt --output weights/yolov8n.torchscript
```

This produces a lightweight `.torchscript` file usable on both Jetson Nano and Raspberry Pi 4.

---

### ðŸŽ¥ 3  Real-Time Inference

Run real-time detection using the integrated inference script:

```bash
python deployment/inference_device.py   --weights weights/yolov8n.torchscript   --source 0   --device cuda:0   --imgsz 640   --conf 0.25
```

**Parameters**
| Argument | Description | Default |
|-----------|--------------|----------|
| `--weights` | Path to model weights (.pt or .torchscript) | Required |
| `--source` | Camera index (0) or video/image path | 0 |
| `--device` | `cpu`, `cuda`, or `cuda:0` | cpu |
| `--imgsz` | Inference image size | 640 |
| `--conf` | Detection confidence threshold | 0.25 |

Press `q` to stop live display.

---

### ðŸ“Š 4  Performance Evaluation (Table 10 Reproduction)

To replicate Table 10 (â€œReal-time embedded performanceâ€), use the inference script on the device and record average FPS as reported below (these are the values reported in the manuscript):

| Device | Model | FPS (avg) | Power (W) | Notes |
|---------|--------|-----------|-----------|-------|
| Jetson Nano | YOLOv4-Darknet53 | 6 | 10 | Baseline YOLOv4 on Jetson Nano |
| Jetson Nano | YOLOv5-s | 8 | 10 | Lightweight YOLOv5-s; real-time on Nano |
| Jetson Nano | YOLOv8-n | 7 | 10 | YOLOv8-n accuracy vs speed tradeoff |
| Raspberry Pi 4 | YOLOv4-Darknet53 | 3 | 8 | CPU-bound |
| Raspberry Pi 4 | YOLOv5-s | 2.5 | 8 | Lightweight variant on Pi |
| Raspberry Pi 4 | YOLOv8-n | 2 | 8 | CPU-bound, lower FPS |

> Notes:
> - Power values are approximate measured draw under typical inference (see manuscript Table 10 for exact measurement setup).
> - For exact reproduction, run `python deployment/inference_device.py --weights <path> --source <camera_or_video> --device cpu` (on Pi use `--device cpu`).

---

### ðŸ§¾ 5  Troubleshooting

| Issue | Possible Cause | Fix |
|-------|----------------|-----|
| *TorchScript load error* | PyTorch version mismatch | Re-export with local PyTorch version |
| *Low FPS on Pi 4* | Missing OpenBLAS / NEON | Enable via `sudo apt install libopenblas-dev` |
| *No display window* | Running headless | Use `--source video.mp4` and log FPS only |

---

### ðŸ”’ 6  Reproducibility & Citation

All deployment configurations, pretrained weights, and scripts are provided under  
ðŸ“‚ `/deployment` and ðŸ“‚ `/weights` in the public repository:  
ðŸ‘‰ https://github.com/OrangeFruitNet-Project/IJIES-2025

If you use this deployment setup, please cite:

> **M. Khedkar et al.**, *â€œOrangeFruitNet: YOLO-Based Orange Fruit Detection and Yield Estimation in Orchard Environments,.....
